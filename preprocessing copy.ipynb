{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d59a9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7090b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchaudio\n",
    "from torchaudio.transforms import MelSpectrogram\n",
    "\n",
    "from params import sample_rate, windowed_signal_length, num_mel_bands, overlap, hop_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be58823d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelSpecPipeline(torch.nn.Module):\n",
    "    def __init__(self, n_fft=windowed_signal_length, sample_rate=sample_rate, n_mel=num_mel_bands):\n",
    "        super().__init__()\n",
    "        self.mel_spec = MelSpectrogram(sample_rate=sample_rate, n_fft=n_fft, n_mels=n_mel, power=2, center=False, hop_length=hop_length)\n",
    "\n",
    "    def forward(self, wave):\n",
    "        assert wave.shape[0] == 1\n",
    "\n",
    "        mel_spec = self.mel_spec(wave)\n",
    "        return mel_spec\n",
    "    \n",
    "pipeline = MelSpecPipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e3d0f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(124.63, 136.975), (72.876, 82.036), (194.072, 205.542), (158.155, 162.49), (0.582, 16.477), (233.761, 246.866), (14.198, 25.438), (262.443, 270.543), (90.981, 106.051), (273.033, 288.833), (52.268, 68.272), (137.211, 151.031), (250.985, 265.71), (273.62, 287.805), (123.585, 134.32), (98.198, 112.692), (207.596, 223.196), (208.436, 220.976), (234.433, 249.023)}\n",
      "covered length is 243.21300000000002, percentage of recording: 0.486426\n",
      "Shape of mels: torch.Size([40, 18685])\n",
      "mel_length_time: 0.656\n",
      "mel_slice_start: 18640, mel_slice_end: 18680, mel_time_start: 12227.84, mel_time_end: 12228.496000000001\n",
      "ratio of speech to non-speech labels: 1.74%\n"
     ]
    }
   ],
   "source": [
    "def check_audio_metadata(metadata):\n",
    "    assert metadata.sample_rate == 16000\n",
    "    assert metadata.num_channels == 1\n",
    "    assert metadata.num_frames > 0\n",
    "\n",
    "def speechOverlap(mel_time_start, mel_time_end, speech_segments):\n",
    "    for speech_start, speech_end in speech_segments:\n",
    "        if speech_start < mel_time_end and mel_time_start < speech_end:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def createDataFromRecording(session_root, id):\n",
    "    wav_path = session_root + \"/session_\" + str(id) + \"_mixture.wav\"\n",
    "    json_path = session_root + \"/session_\" + str(id) + \".json\"\n",
    "\n",
    "    # check some metadata\n",
    "    metadata = torchaudio.info(wav_path)\n",
    "    check_audio_metadata(metadata)\n",
    "    # print(f'Metadata: {metadata}')\n",
    "\n",
    "    # retrieve speech segments\n",
    "    speech_segments = set()\n",
    "    with open(json_path, 'r') as f:\n",
    "        speech_info = json.load(f)\n",
    "    for key in speech_info:\n",
    "        if key.isdigit():\n",
    "            for info in speech_info[key]:\n",
    "                segment = (info[\"start\"], info[\"stop\"])\n",
    "                assert segment[0] < segment[1]\n",
    "                speech_segments.add(segment)\n",
    "    print(speech_segments)\n",
    "\n",
    "    covered = sum([end - start for start, end in speech_segments])\n",
    "    print(f'covered length is {covered}, percentage of recording: {covered / 500}')\n",
    "\n",
    "    # MFSC pipeline\n",
    "    wave, _ = torchaudio.load(wav_path)\n",
    "    mels = pipeline(wave)\n",
    "    mels.squeeze_(0)\n",
    "    # librosa.display.specshow(mels.numpy())\n",
    "    print(f'Shape of mels: {mels.shape}')\n",
    "    num_data = mels.shape[1] // (num_mel_bands // overlap)\n",
    "\n",
    "    mel_length_time = ((num_mel_bands - 1) * hop_length + windowed_signal_length) / sample_rate\n",
    "    print(f'mel_length_time: {mel_length_time}')\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(num_data - 1):\n",
    "        mel_slice_start = i * (num_mel_bands // overlap)\n",
    "        mel_slice_end = mel_slice_start + num_mel_bands\n",
    "\n",
    "        mel_time_start = mel_slice_start * mel_length_time\n",
    "        mel_time_end = mel_time_start + mel_length_time\n",
    "\n",
    "        X.append(mels[:, mel_slice_start : mel_slice_end].clone().detach())\n",
    "        y.append(torch.ones(1) if speechOverlap(mel_time_start, mel_time_end, speech_segments) else torch.zeros(1))\n",
    "\n",
    "        if i == num_data - 2:\n",
    "            # print the 4 mel values above\n",
    "            print(f'mel_slice_start: {mel_slice_start}, mel_slice_end: {mel_slice_end}, mel_time_start: {mel_time_start}, mel_time_end: {mel_time_end}')\n",
    "\n",
    "    X = torch.cat(X, dim=0)\n",
    "    y = torch.cat(y, dim=0)\n",
    "    return X, y\n",
    "\n",
    "X, y = createDataFromRecording(session_root=\"LibriParty/dataset/train/session_0\", id=0)\n",
    "print(f'ratio of speech to non-speech labels: {((y==1).sum() / (y==0).sum() * 100):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7385b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(80.508, 86.318), (292.097, 295.067), (107.296, 112.546), (6.534, 8.979), (144.639, 149.959), (22.107, 33.907), (204.186, 211.701), (11.362, 15.032), (200.045, 203.305), (71.537, 83.347), (186.035, 191.6), (0.32, 3.755), (288.428, 291.808), (104.604, 116.529), (69.919, 74.559), (161.507, 163.797), (281.816, 284.891), (38.728, 41.183), (203.426, 216.331), (66.846, 70.546), (120.617, 123.707), (85.125, 89.15)}\n",
      "Shape of mels: torch.Size([40, 18440])\n",
      "mel_length_time: 0.656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\afkhe\\AppData\\Local\\Temp\\ipykernel_34352\\3830253905.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X.append(torch.tensor(mels[:, mel_slice_start : mel_slice_end]))\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my.shape is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n\u001b[1;32m---> 18\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcreateDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLibriParty/dataset/dev/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_sessions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 7\u001b[0m, in \u001b[0;36mcreateDataset\u001b[1;34m(root, num_sessions)\u001b[0m\n\u001b[0;32m      5\u001b[0m session_X, session_y \u001b[38;5;241m=\u001b[39m createDataFromRecording(session_root\u001b[38;5;241m=\u001b[39mroot \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msession_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(session), \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39msession)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_tensor(session_X) \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_tensor(session_y) \n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m session_X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m num_mel_bands \u001b[38;5;129;01mand\u001b[39;00m session_X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m num_mel_bands \u001b[38;5;129;01mand\u001b[39;00m \u001b[43msession_y\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m session_X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m session_y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      9\u001b[0m X\u001b[38;5;241m.\u001b[39mappend(session_X)\n\u001b[0;32m     10\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(session_y)\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# def createDataset(root, num_sessions):\n",
    "#     X = []\n",
    "#     y = []\n",
    "#     for session in range(num_sessions):\n",
    "#         session_X, session_y = createDataFromRecording(session_root=root + \"session_\" + str(session), id=session)\n",
    "#         assert torch.is_tensor(session_X) and torch.is_tensor(session_y) \n",
    "#         assert session_X.shape[1] == num_mel_bands and session_X.shape[1] == num_mel_bands and session_y.shape[1] == 1 and session_X.shape[0] == session_y.shape[0]\n",
    "\n",
    "#         X.append(session_X)\n",
    "#         y.append(session_y)\n",
    "#     X = torch.cat(X, dim=0)\n",
    "#     y = torch.cat(y, dim=0)\n",
    "\n",
    "#     print(f'X.shape is: {X.shape}')\n",
    "#     print(f'y.shape is: {y.shape}')\n",
    "#     return X, y\n",
    "\n",
    "# X, y = createDataset(root='LibriParty/dataset/dev/', num_sessions=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d24a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num 0s: 44935\n",
      "num 1s: 551\n"
     ]
    }
   ],
   "source": [
    "print(f'num 0s: {(y==0).sum()}')\n",
    "print(f'num 1s: {(y==1).sum()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSP_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
