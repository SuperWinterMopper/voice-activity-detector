{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d59a9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d7090b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import os\n",
    "import math\n",
    "import argparse\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Dict\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy.fft import fft, fftshift\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchaudio\n",
    "from torchaudio.transforms import MelSpectrogram, AmplitudeToDB, TimeMasking, FrequencyMasking\n",
    "\n",
    "from params import sample_rate, windowed_signal_length, num_mel_bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be58823d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelSpecPipeline(torch.nn.Module):\n",
    "    def __init__(self, n_fft=windowed_signal_length, sample_rate=sample_rate, n_mel=num_mel_bands):\n",
    "        super().__init__()\n",
    "        self.mel_spec = MelSpectrogram(sample_rate=sample_rate, n_fft=n_fft, n_mels=n_mel, power=2)\n",
    "\n",
    "    def forward(self, wave):\n",
    "        assert wave.shape[0] == 1\n",
    "\n",
    "        mel_spec = self.mel_spec(wave)\n",
    "        # assert mel_spec.shape == (40, 40)\n",
    "\n",
    "        return mel_spec\n",
    "    \n",
    "pipeline = MelSpecPipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0e3d0f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4783692, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "Shape of mel_spec: torch.Size([40, 18687])\n",
      "{(124.63, 136.975), (72.876, 82.036), (194.072, 205.542), (158.155, 162.49), (0.582, 16.477), (233.761, 246.866), (14.198, 25.438), (262.443, 270.543), (90.981, 106.051), (273.033, 288.833), (52.268, 68.272), (137.211, 151.031), (250.985, 265.71), (273.62, 287.805), (123.585, 134.32), (98.198, 112.692), (207.596, 223.196), (208.436, 220.976), (234.433, 249.023)}\n"
     ]
    }
   ],
   "source": [
    "def check_audio_metadata(metadata):\n",
    "    assert metadata.sample_rate == 16000\n",
    "    assert metadata.num_channels == 1\n",
    "    assert metadata.num_frames > 0\n",
    "\n",
    "\n",
    "def createDataFromRecording(session_root, id):\n",
    "    wav_path = session_root + \"/session_\" + str(id) + \"_mixture.wav\"\n",
    "    json_path = session_root + \"/session_\" + str(id) + \".json\"\n",
    "\n",
    "    metadata = torchaudio.info(wav_path)\n",
    "    check_audio_metadata(metadata)\n",
    "    print(f'Metadata: {metadata}')\n",
    "\n",
    "    # MFSC pipeline\n",
    "    ys, _ = torchaudio.load(wav_path)\n",
    "    mel_spec = pipeline(ys)\n",
    "    mel_spec.squeeze_(0)\n",
    "    # librosa.display.specshow(mel_spec.numpy())\n",
    "    print(f'Shape of mel_spec: {mel_spec.shape}')\n",
    "\n",
    "    speech_segments = set()\n",
    "\n",
    "    with open(json_path, 'r') as f:\n",
    "        speech_info = json.load(f)\n",
    "    for key in speech_info:\n",
    "        if key.isdigit():\n",
    "            for info in speech_info[key]:\n",
    "                segment = (info[\"start\"], info[\"stop\"])\n",
    "                assert segment[0] < segment[1]\n",
    "                speech_segments.add(segment)\n",
    "    \n",
    "    print(speech_segments)\n",
    "\n",
    "\n",
    "    \n",
    "createDataFromRecording(session_root=\"LibriParty/dataset/train/session_0\", id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7385b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSP_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
