{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d59a9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7090b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import os\n",
    "import math\n",
    "import argparse\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy.fft import fft, fftshift\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchaudio\n",
    "from torchaudio.transforms import MelSpectrogram, AmplitudeToDB, TimeMasking, FrequencyMasking\n",
    "\n",
    "from params import sample_rate, windowed_signal_length, num_mel_bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be58823d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "class MyPipeline(torch.nn.Module):\n",
    "    def __init__(self, n_fft, sample_rate, n_mel):\n",
    "        super().__init__()\n",
    "        self.mel_spec = MelSpectrogram(sample_rate=sample_rate, n_fft=n_fft, n_mels=n_mel)\n",
    "    def forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3d0f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AudioMetaData(sample_rate=16000, num_frames=4783692, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n"
     ]
    }
   ],
   "source": [
    "def check_audio_metadata(metadata):\n",
    "    assert metadata.sample_rate == 16000\n",
    "    assert metadata.num_channels == 1\n",
    "    assert metadata.num_frames > 0\n",
    "\n",
    "\n",
    "def createDataFromRecording(session_root, id, ):\n",
    "    wav_path = session_root + \"/session_\" + str(id) + \"_mixture.wav\"\n",
    "    json_path = session_root + \"/session_\" + str(id) + \".json\"\n",
    "\n",
    "    metadata = torchaudio.info(wav_path)\n",
    "    check_audio_metadata(metadata)\n",
    "\n",
    "    print(metadata)\n",
    "\n",
    "createDataFromRecording(session_root=\"LibriParty/dataset/train/session_0\", id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df976626",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSP_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
