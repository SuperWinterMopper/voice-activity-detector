{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d59a9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7090b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchaudio\n",
    "from torchaudio.transforms import MelSpectrogram\n",
    "\n",
    "from params import sample_rate, windowed_signal_length, num_mel_bands, overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be58823d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelSpecPipeline(torch.nn.Module):\n",
    "    def __init__(self, n_fft=windowed_signal_length, sample_rate=sample_rate, n_mel=num_mel_bands):\n",
    "        super().__init__()\n",
    "        self.mel_spec = MelSpectrogram(sample_rate=sample_rate, n_fft=n_fft, n_mels=n_mel, power=2)\n",
    "\n",
    "    def forward(self, wave):\n",
    "        assert wave.shape[0] == 1\n",
    "\n",
    "        mel_spec = self.mel_spec(wave)\n",
    "        return mel_spec\n",
    "    \n",
    "pipeline = MelSpecPipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e3d0f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4783692, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(124.63, 136.975), (72.876, 82.036), (194.072, 205.542), (158.155, 162.49), (0.582, 16.477), (233.761, 246.866), (14.198, 25.438), (262.443, 270.543), (90.981, 106.051), (273.033, 288.833), (52.268, 68.272), (137.211, 151.031), (250.985, 265.71), (273.62, 287.805), (123.585, 134.32), (98.198, 112.692), (207.596, 223.196), (208.436, 220.976), (234.433, 249.023)}\n",
      "Shape of mels: torch.Size([40, 18687])\n",
      "mel_length_time: 1.28\n",
      "num_data: 934\n",
      "X.shape is torch.Size([934, 40, 40])\n",
      "y.shape is torch.Size([934, 1])\n"
     ]
    }
   ],
   "source": [
    "def check_audio_metadata(metadata):\n",
    "    assert metadata.sample_rate == 16000\n",
    "    assert metadata.num_channels == 1\n",
    "    assert metadata.num_frames > 0\n",
    "\n",
    "def createDataFromRecording(session_root, id):\n",
    "    wav_path = session_root + \"/session_\" + str(id) + \"_mixture.wav\"\n",
    "    json_path = session_root + \"/session_\" + str(id) + \".json\"\n",
    "\n",
    "    # check some metadata\n",
    "    metadata = torchaudio.info(wav_path)\n",
    "    check_audio_metadata(metadata)\n",
    "    print(f'Metadata: {metadata}')\n",
    "\n",
    "    # retrieve speech segments\n",
    "    speech_segments = set()\n",
    "    with open(json_path, 'r') as f:\n",
    "        speech_info = json.load(f)\n",
    "    for key in speech_info:\n",
    "        if key.isdigit():\n",
    "            for info in speech_info[key]:\n",
    "                segment = (info[\"start\"], info[\"stop\"])\n",
    "                assert segment[0] < segment[1]\n",
    "                speech_segments.add(segment)\n",
    "    print(speech_segments)\n",
    "\n",
    "    # MFSC pipeline\n",
    "    wave, _ = torchaudio.load(wav_path)\n",
    "    mels = pipeline(wave)\n",
    "    mels.squeeze_(0)\n",
    "    # librosa.display.specshow(mels.numpy())\n",
    "    print(f'Shape of mels: {mels.shape}')\n",
    "\n",
    "    mel_length_time = (windowed_signal_length * num_mel_bands) / sample_rate\n",
    "    print(f'mel_length_time: {mel_length_time}')\n",
    "\n",
    "    num_data = mels.shape[1] // num_mel_bands * overlap\n",
    "    print(f'num_data: {num_data}')\n",
    "\n",
    "    X = [torch.ones(num_mel_bands, num_mel_bands) for _ in range(num_data)]\n",
    "    y = [torch.zeros(1) for _  in range(num_data)]\n",
    "\n",
    "    # we iterate over all complete mel bands possible. \n",
    "    # We drop the end bit of the recording if it isn't long enough for a whole MFSC spectrogram\n",
    "    # We process with overlaps of 1/`overlap`\n",
    "    for output_i, mel_i in enumerate(range(0, int(mels.shape[1] - num_mel_bands), num_mel_bands // overlap)):\n",
    "        mel_start_time = mel_i * mel_length_time\n",
    "        mel_end_time = (mel_i + 1) * mel_length_time\n",
    "\n",
    "        for start, end in speech_segments:\n",
    "            if mel_start_time < end and start < mel_end_time:\n",
    "                y[output_i] = torch.ones(1)\n",
    "        X[output_i] = mels[:, mel_i : mel_i + num_mel_bands].clone().detach()\n",
    "        # print(f'X[{output_i}].shape: {X[output_i].shape}')\n",
    "        # print(f'y shape: {y[output_i].shape}')\n",
    "        assert X[output_i].shape == (num_mel_bands, num_mel_bands)\n",
    "        assert y[output_i].shape == (1,)\n",
    "\n",
    "    assert all(isinstance(x, torch.Tensor) for x in X), \"all X entries must be tensors\"\n",
    "    assert all(x.shape == (num_mel_bands, num_mel_bands) for x in X), \"inconsistent X shapes\"\n",
    "    assert all(isinstance(t, torch.Tensor) for t in y), \"all y entries must be tensors\"\n",
    "\n",
    "    X = torch.stack(X, dim=0)\n",
    "    y = torch.stack(y, dim=0)\n",
    "\n",
    "    print(f'X.shape is {X.shape}')\n",
    "    print(f'y.shape is {y.shape}')\n",
    "    return X, y\n",
    "\n",
    "X, y = createDataFromRecording(session_root=\"LibriParty/dataset/train/session_0\", id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e7385b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4721080, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(80.508, 86.318), (292.097, 295.067), (107.296, 112.546), (6.534, 8.979), (144.639, 149.959), (22.107, 33.907), (204.186, 211.701), (11.362, 15.032), (200.045, 203.305), (71.537, 83.347), (186.035, 191.6), (0.32, 3.755), (288.428, 291.808), (104.604, 116.529), (69.919, 74.559), (161.507, 163.797), (281.816, 284.891), (38.728, 41.183), (203.426, 216.331), (66.846, 70.546), (120.617, 123.707), (85.125, 89.15)}\n",
      "Shape of mels: torch.Size([40, 18442])\n",
      "mel_length_time: 1.28\n",
      "num_data: 922\n",
      "X.shape is torch.Size([922, 40, 40])\n",
      "y.shape is torch.Size([922, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4353202, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(14.381, 24.836), (218.954, 221.939), (176.612, 183.372), (78.457, 82.312), (143.88, 148.945), (268.635, 272.075), (96.389, 103.999), (251.115, 258.56), (132.073, 135.093), (246.278, 253.308), (100.741, 104.906), (130.091, 141.246), (216.255, 222.64), (157.807, 161.502), (1.595, 4.12), (84.552, 87.967), (198.706, 202.876), (67.991, 78.606), (106.9, 126.655), (30.928, 58.918), (144.379, 165.549), (107.437, 112.592), (128.817, 131.942), (225.074, 231.844)}\n",
      "Shape of mels: torch.Size([40, 17005])\n",
      "mel_length_time: 1.28\n",
      "num_data: 850\n",
      "X.shape is torch.Size([850, 40, 40])\n",
      "y.shape is torch.Size([850, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4675329, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(155.29, 164.74), (222.807, 231.817), (79.959, 83.984), (255.445, 261.445), (271.954, 276.209), (241.233, 247.868), (286.233, 292.208), (159.602, 165.282), (174.24, 180.81), (213.113, 216.813), (278.013, 282.768), (112.85, 118.71), (84.869, 90.679), (135.465, 147.72), (266.352, 275.077), (190.752, 194.552), (204.264, 208.914), (119.891, 124.831)}\n",
      "Shape of mels: torch.Size([40, 18264])\n",
      "mel_length_time: 1.28\n",
      "num_data: 912\n",
      "X.shape is torch.Size([912, 40, 40])\n",
      "y.shape is torch.Size([912, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4773959, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(118.555, 123.75), (167.181, 176.006), (278.272, 280.277), (247.923, 258.238), (269.365, 277.71), (57.055, 59.425), (23.871, 28.571), (240.944, 244.704), (65.567, 67.012), (294.397, 298.372), (127.1, 136.55), (25.881, 29.931), (10.451, 14.231), (159.382, 165.302), (149.272, 154.282), (276.171, 285.791), (224.135, 234.73), (200.214, 203.789), (145.831, 148.566), (286.454, 296.154), (190.49, 194.805), (137.404, 146.199), (200.017, 211.337), (214.198, 216.918), (138.186, 143.841)}\n",
      "Shape of mels: torch.Size([40, 18649])\n",
      "mel_length_time: 1.28\n",
      "num_data: 932\n",
      "X.shape is torch.Size([932, 40, 40])\n",
      "y.shape is torch.Size([932, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4659539, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(254.53, 260.24), (69.286, 78.021), (157.24, 162.22), (166.625, 170.09), (155.59, 159.505), (189.056, 192.766), (219.287, 223.047), (51.573, 59.983), (122.997, 127.542), (180.148, 185.018), (204.144, 212.864), (273.606, 291.221), (95.972, 113.167), (137.029, 139.679), (86.196, 94.711), (225.952, 234.102), (181.065, 189.505), (96.281, 101.841), (28.772, 38.992), (25.451, 28.001), (146.03, 152.784)}\n",
      "Shape of mels: torch.Size([40, 18202])\n",
      "mel_length_time: 1.28\n",
      "num_data: 910\n",
      "X.shape is torch.Size([910, 40, 40])\n",
      "y.shape is torch.Size([910, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4551549, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(17.383, 23.353), (29.057, 39.947), (250.482, 253.687), (187.738, 206.083), (41.365, 44.7), (144.952, 158.442), (254.868, 264.868), (107.695, 119.57), (123.414, 127.174), (203.888, 206.113), (209.527, 220.607), (249.05, 266.82), (1.995, 4.495), (141.902, 143.932), (238.38, 240.855), (81.712, 93.682), (30.95, 45.18), (189.202, 192.962), (115.2, 117.75), (134.342, 139.587), (280.232, 284.472), (72.836, 77.061)}\n",
      "Shape of mels: torch.Size([40, 17780])\n",
      "mel_length_time: 1.28\n",
      "num_data: 888\n",
      "X.shape is torch.Size([888, 40, 40])\n",
      "y.shape is torch.Size([888, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4597376, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(1.091, 11.361), (61.349, 70.264), (64.38, 67.63), (92.183, 100.123), (16.2, 24.225), (284.081, 287.336), (137.797, 144.147), (162.119, 179.099), (267.668, 281.568), (155.023, 158.288), (260.829, 267.444), (115.14, 123.485), (6.619, 9.869), (32.031, 39.616), (221.747, 233.067), (215.728, 222.343), (101.439, 110.234), (103.972, 107.102), (28.732, 38.232), (235.362, 244.098), (53.044, 58.059)}\n",
      "Shape of mels: torch.Size([40, 17959])\n",
      "mel_length_time: 1.28\n",
      "num_data: 896\n",
      "X.shape is torch.Size([896, 40, 40])\n",
      "y.shape is torch.Size([896, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4735547, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(177.486, 180.041), (63.248, 70.978), (98.761, 105.521), (111.399, 121.829), (93.606, 96.826), (20.669, 27.069), (264.52, 272.195), (235.805, 238.61), (84.439, 86.809), (156.112, 158.132), (200.623, 205.193), (257.459, 263.889), (209.102, 215.092), (52.973, 55.208), (30.62, 35.414), (248.077, 251.772), (152.063, 154.528), (12.269, 21.039), (196.31, 198.9), (222.784, 225.378), (281.541, 291.631), (218.559, 221.719), (225.529, 228.939), (239.155, 244.86), (139.025, 145.13), (187.851, 192.691), (33.48, 37.675), (165.103, 175.823), (129.626, 132.111), (288.772, 295.972), (75.318, 81.573)}\n",
      "Shape of mels: torch.Size([40, 18499])\n",
      "mel_length_time: 1.28\n",
      "num_data: 924\n",
      "X.shape is torch.Size([924, 40, 40])\n",
      "y.shape is torch.Size([924, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4778975, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(203.324, 210.764), (39.572, 47.642), (174.922, 177.517), (74.905, 85.88), (101.257, 103.752), (12.953, 23.358), (48.01, 56.715), (90.143, 98.038), (152.042, 155.072), (113.122, 122.812), (27.668, 45.003), (180.974, 184.509), (256.9, 262.764), (138.407, 141.702), (216.186, 220.361), (205.436, 208.591), (46.17, 62.52), (111.736, 119.081), (236.501, 241.731), (148.054, 158.329), (89.905, 94.285), (106.752, 110.602), (268.761, 276.436), (210.487, 213.367)}\n",
      "Shape of mels: torch.Size([40, 18668])\n",
      "mel_length_time: 1.28\n",
      "num_data: 932\n",
      "X.shape is torch.Size([932, 40, 40])\n",
      "y.shape is torch.Size([932, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4728037, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(241.228, 247.298), (172.102, 176.257), (290.522, 295.502), (196.387, 200.887), (204.508, 208.788), (164.295, 168.15), (50.625, 59.205), (47.821, 51.996), (55.906, 70.116), (273.41, 285.305), (266.071, 269.541), (212.11, 219.65), (3.608, 6.078), (212.905, 219.02), (72.036, 80.721), (181.727, 190.292), (220.293, 223.933), (76.676, 86.156), (12.179, 14.439), (94.861, 101.676), (226.133, 233.533), (158.662, 171.847), (93.897, 103.467), (41.876, 47.411), (29.416, 34.696)}\n",
      "Shape of mels: torch.Size([40, 18469])\n",
      "mel_length_time: 1.28\n",
      "num_data: 922\n",
      "X.shape is torch.Size([922, 40, 40])\n",
      "y.shape is torch.Size([922, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4713225, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(164.957, 173.342), (24.987, 35.482), (6.016, 9.566), (158.053, 170.598), (80.991, 86.001), (35.881, 49.781), (19.824, 23.324), (134.907, 137.342), (256.848, 260.114), (286.392, 294.576), (58.094, 67.02), (252.326, 260.546), (198.277, 201.162), (209.57, 218.955), (116.547, 126.712), (99.454, 103.504), (235.967, 245.067), (30.805, 38.78), (42.59, 47.405), (203.405, 212.235), (196.962, 206.172)}\n",
      "Shape of mels: torch.Size([40, 18412])\n",
      "mel_length_time: 1.28\n",
      "num_data: 920\n",
      "X.shape is torch.Size([920, 40, 40])\n",
      "y.shape is torch.Size([920, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4700165, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(164.584, 169.839), (153.062, 157.732), (89.468, 94.293), (80.874, 83.379), (223.453, 226.913), (12.38, 15.225), (272.119, 280.734), (36.524, 40.284), (108.748, 113.393), (75.878, 80.283), (252.832, 255.982), (133.579, 139.764), (228.801, 238.086), (11.36, 16.17), (290.205, 293.76), (224.45, 228.395), (264.711, 271.731), (217.731, 220.421), (51.73, 57.72), (116.657, 120.457)}\n",
      "Shape of mels: torch.Size([40, 18361])\n",
      "mel_length_time: 1.28\n",
      "num_data: 918\n",
      "X.shape is torch.Size([918, 40, 40])\n",
      "y.shape is torch.Size([918, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4788980, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(184.029, 192.799), (229.243, 236.263), (287.577, 293.162), (76.302, 85.372), (160.722, 178.892), (149.73, 152.95), (236.805, 239.61), (266.709, 278.964), (19.864, 23.384), (131.81, 138.275), (199.031, 202.416), (113.382, 117.672), (28.464, 32.264), (259.691, 271.486), (276.921, 280.906), (287.128, 293.188), (45.723, 52.753), (238.156, 243.101), (69.394, 76.164), (294.251, 299.311), (295.286, 297.236), (247.014, 251.578), (172.688, 180.088)}\n",
      "Shape of mels: torch.Size([40, 18707])\n",
      "mel_length_time: 1.28\n",
      "num_data: 934\n",
      "X.shape is torch.Size([934, 40, 40])\n",
      "y.shape is torch.Size([934, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4763173, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(103.052, 108.812), (86.124, 89.419), (26.512, 30.667), (129.755, 132.5), (53.949, 57.894), (290.033, 297.698), (169.438, 174.418), (176.35, 182.465), (148.057, 154.277), (284.311, 287.466), (216.642, 223.987), (234.149, 237.999), (231.655, 234.0), (234.833, 248.398), (116.143, 125.238)}\n",
      "Shape of mels: torch.Size([40, 18607])\n",
      "mel_length_time: 1.28\n",
      "num_data: 930\n",
      "X.shape is torch.Size([930, 40, 40])\n",
      "y.shape is torch.Size([930, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4676043, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(67.51, 70.075), (281.073, 292.253), (164.914, 180.198), (202.468, 210.188), (100.13, 104.58), (148.704, 157.829), (95.181, 103.031), (70.478, 85.498), (185.185, 196.54), (254.196, 268.391), (32.061, 41.956), (113.681, 117.711), (42.372, 46.887), (239.407, 246.127), (105.242, 117.897), (236.198, 250.248), (149.056, 163.511), (203.712, 219.232)}\n",
      "Shape of mels: torch.Size([40, 18266])\n",
      "mel_length_time: 1.28\n",
      "num_data: 912\n",
      "X.shape is torch.Size([912, 40, 40])\n",
      "y.shape is torch.Size([912, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4695702, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(82.65, 91.9), (96.559, 101.574), (185.773, 189.438), (261.908, 267.463), (288.949, 291.889), (124.86, 145.08), (202.579, 206.744), (49.401, 59.141), (20.15, 24.625), (60.95, 74.905), (140.913, 148.358), (197.01, 199.915), (157.287, 159.477), (175.916, 182.901), (93.007, 112.357), (207.512, 217.722), (244.123, 246.593)}\n",
      "Shape of mels: torch.Size([40, 18343])\n",
      "mel_length_time: 1.28\n",
      "num_data: 916\n",
      "X.shape is torch.Size([916, 40, 40])\n",
      "y.shape is torch.Size([916, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4536129, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(174.996, 185.766), (137.305, 147.17), (64.366, 67.611), (205.987, 211.082), (75.298, 82.338), (93.264, 104.769), (184.601, 188.371), (103.185, 110.33), (153.198, 156.358), (281.043, 283.508), (65.765, 69.075), (150.253, 153.053), (35.404, 41.394), (245.742, 248.712), (216.518, 226.608), (117.569, 121.194), (68.282, 71.122), (186.685, 189.67), (30.073, 33.483), (175.819, 181.759), (9.388, 13.888), (198.926, 204.311), (157.148, 163.688), (143.597, 146.437)}\n",
      "Shape of mels: torch.Size([40, 17720])\n",
      "mel_length_time: 1.28\n",
      "num_data: 886\n",
      "X.shape is torch.Size([886, 40, 40])\n",
      "y.shape is torch.Size([886, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4777016, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(121.902, 137.122), (68.445, 75.965), (217.865, 234.61), (106.949, 109.019), (188.172, 191.932), (172.574, 175.989), (195.148, 197.548), (112.372, 129.232), (204.079, 217.259), (48.076, 50.846), (22.519, 31.099), (82.363, 87.198), (100.126, 102.981), (29.618, 44.048), (224.98, 241.29), (256.47, 268.565), (291.198, 298.563), (250.249, 253.259), (261.98, 264.125), (20.311, 24.571), (76.165, 80.5)}\n",
      "Shape of mels: torch.Size([40, 18661])\n",
      "mel_length_time: 1.28\n",
      "num_data: 932\n",
      "X.shape is torch.Size([932, 40, 40])\n",
      "y.shape is torch.Size([932, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4720799, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(53.874, 56.784), (289.085, 295.05), (159.129, 161.834), (180.367, 186.577), (239.731, 259.951), (95.424, 103.134), (137.369, 140.044), (17.956, 34.626), (186.939, 190.749), (68.77, 83.7), (49.425, 50.985), (17.206, 32.191), (222.156, 224.961), (219.836, 232.526), (4.947, 8.612), (81.177, 89.032), (162.04, 164.825), (160.444, 164.919), (104.102, 119.042), (128.269, 132.749)}\n",
      "Shape of mels: torch.Size([40, 18441])\n",
      "mel_length_time: 1.28\n",
      "num_data: 922\n",
      "X.shape is torch.Size([922, 40, 40])\n",
      "y.shape is torch.Size([922, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4603490, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(121.661, 138.641), (54.957, 77.327), (175.437, 179.387), (83.006, 85.011), (159.731, 166.141), (151.835, 154.72), (91.966, 99.94), (201.171, 229.741), (207.52, 218.84), (238.455, 244.105), (96.139, 98.409), (8.642, 18.026), (116.698, 128.788), (144.793, 154.243), (225.929, 232.044), (248.887, 257.802), (275.01, 284.13), (35.279, 40.579), (0.849, 4.894)}\n",
      "Shape of mels: torch.Size([40, 17983])\n",
      "mel_length_time: 1.28\n",
      "num_data: 898\n",
      "X.shape is torch.Size([898, 40, 40])\n",
      "y.shape is torch.Size([898, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4719527, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(36.945, 39.805), (20.217, 22.407), (79.524, 81.764), (197.1, 203.96), (269.806, 288.761), (155.826, 170.286), (189.495, 191.66), (128.316, 135.051), (264.243, 270.293), (172.404, 174.894), (283.397, 288.587), (5.451, 9.666), (144.393, 148.718), (68.308, 84.008), (100.735, 129.53), (152.921, 167.851), (43.538, 46.353), (215.018, 229.313), (149.504, 155.53), (275.788, 278.958), (249.12, 259.0), (93.848, 96.423), (232.078, 251.193)}\n",
      "Shape of mels: torch.Size([40, 18436])\n",
      "mel_length_time: 1.28\n",
      "num_data: 920\n",
      "X.shape is torch.Size([920, 40, 40])\n",
      "y.shape is torch.Size([920, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4568572, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(21.917, 27.497), (238.281, 241.711), (44.289, 53.869), (194.94, 198.34), (220.456, 235.26), (150.071, 154.021), (244.846, 256.942), (161.993, 166.043), (281.591, 285.536), (73.224, 81.414), (125.398, 136.253), (215.887, 234.812), (121.771, 126.316), (169.72, 176.04), (263.802, 274.212), (27.134, 36.314), (201.213, 206.448), (271.177, 281.527), (11.189, 17.179), (194.383, 198.143)}\n",
      "Shape of mels: torch.Size([40, 17846])\n",
      "mel_length_time: 1.28\n",
      "num_data: 892\n",
      "X.shape is torch.Size([892, 40, 40])\n",
      "y.shape is torch.Size([892, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4453133, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(267.566, 278.321), (45.656, 52.081), (218.828, 224.298), (247.107, 253.207), (233.09, 236.64), (247.585, 250.835), (213.776, 216.521), (208.345, 212.395), (222.267, 230.262), (97.356, 109.901), (13.412, 22.587), (270.472, 277.732), (106.652, 115.472), (160.875, 164.23), (57.331, 62.316), (18.27, 25.724), (186.706, 195.621), (241.972, 244.062), (237.762, 246.972), (65.471, 70.486), (186.212, 194.767), (73.868, 78.183)}\n",
      "Shape of mels: torch.Size([40, 17396])\n",
      "mel_length_time: 1.28\n",
      "num_data: 868\n",
      "X.shape is torch.Size([868, 40, 40])\n",
      "y.shape is torch.Size([868, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4606588, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(246.047, 251.702), (150.994, 153.024), (108.313, 114.258), (209.632, 213.657), (168.087, 170.187), (281.436, 286.631), (135.671, 139.556), (38.306, 49.811), (195.316, 199.456), (263.073, 266.173), (89.412, 92.467), (99.168, 101.238), (218.585, 221.135), (109.779, 123.654), (207.203, 215.373), (285.032, 287.912), (256.835, 260.045), (234.612, 251.012), (77.88, 84.855)}\n",
      "Shape of mels: torch.Size([40, 17995])\n",
      "mel_length_time: 1.28\n",
      "num_data: 898\n",
      "X.shape is torch.Size([898, 40, 40])\n",
      "y.shape is torch.Size([898, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4727486, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(187.06, 203.805), (31.734, 42.799), (232.493, 235.513), (109.466, 113.961), (43.884, 51.304), (274.089, 286.184), (29.507, 34.317), (210.759, 214.239), (290.665, 294.425), (159.183, 178.613), (270.715, 277.18), (71.315, 86.12), (145.929, 156.279), (219.187, 225.347), (21.37, 30.44), (241.158, 259.328), (175.034, 188.634), (245.151, 249.071), (252.592, 262.847), (69.924, 78.048), (290.243, 295.468), (159.497, 166.517), (59.259, 61.794), (194.897, 197.927)}\n",
      "Shape of mels: torch.Size([40, 18467])\n",
      "mel_length_time: 1.28\n",
      "num_data: 922\n",
      "X.shape is torch.Size([922, 40, 40])\n",
      "y.shape is torch.Size([922, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4792970, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(171.688, 174.508), (14.324, 25.714), (274.624, 280.584), (182.414, 189.664), (16.889, 20.064), (66.428, 76.938), (157.064, 168.104), (275.758, 283.243), (83.624, 92.994), (55.212, 59.952), (141.615, 147.785), (231.945, 252.825), (82.427, 90.317), (120.876, 126.691), (289.646, 299.561), (182.747, 186.467), (263.385, 266.85), (95.05, 107.845), (218.071, 227.491), (201.573, 218.188), (131.971, 139.561), (238.254, 243.439), (145.827, 152.472), (157.422, 160.072)}\n",
      "Shape of mels: torch.Size([40, 18723])\n",
      "mel_length_time: 1.28\n",
      "num_data: 936\n",
      "X.shape is torch.Size([936, 40, 40])\n",
      "y.shape is torch.Size([936, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4496297, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(260.103, 261.878), (46.426, 51.911), (119.507, 124.127), (10.893, 19.803), (52.331, 62.636), (148.095, 162.095), (79.078, 87.774), (132.304, 145.984), (203.708, 215.663), (192.7, 202.03), (28.763, 31.783), (217.277, 219.617), (60.536, 64.991), (249.371, 252.781), (257.114, 261.399), (166.923, 173.123), (230.572, 238.417), (75.516, 78.796), (145.396, 154.796), (138.405, 143.305), (242.078, 248.393), (270.344, 272.614), (190.42, 196.68)}\n",
      "Shape of mels: torch.Size([40, 17564])\n",
      "mel_length_time: 1.28\n",
      "num_data: 878\n",
      "X.shape is torch.Size([878, 40, 40])\n",
      "y.shape is torch.Size([878, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4554635, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(15.094, 24.544), (116.232, 119.587), (192.793, 194.798), (233.443, 238.113), (197.554, 206.379), (19.617, 28.902), (128.279, 134.959), (156.29, 166.735), (97.328, 108.724), (148.454, 152.284), (84.594, 90.339), (257.835, 268.635), (79.531, 87.526), (76.41, 81.645), (41.842, 44.177), (63.021, 66.806), (90.588, 99.938), (44.244, 47.374), (213.612, 218.622), (222.77, 227.86), (205.458, 211.593), (35.839, 40.769)}\n",
      "Shape of mels: torch.Size([40, 17792])\n",
      "mel_length_time: 1.28\n",
      "num_data: 888\n",
      "X.shape is torch.Size([888, 40, 40])\n",
      "y.shape is torch.Size([888, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4671489, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(9.593, 18.388), (234.581, 239.416), (65.654, 69.414), (267.946, 284.346), (158.815, 164.76), (139.635, 142.14), (86.393, 88.928), (259.192, 262.398), (112.4, 117.32), (61.635, 65.685), (211.533, 214.743), (83.148, 94.228), (179.58, 182.045), (250.092, 252.317), (78.145, 82.56), (246.785, 249.135), (19.555, 22.855), (65.715, 69.0), (31.301, 46.706), (245.311, 247.481), (186.758, 191.568), (152.248, 155.113), (210.477, 215.122), (117.568, 120.353), (169.235, 172.665), (18.525, 20.895), (289.358, 291.968), (135.54, 138.04)}\n",
      "Shape of mels: torch.Size([40, 18249])\n",
      "mel_length_time: 1.28\n",
      "num_data: 912\n",
      "X.shape is torch.Size([912, 40, 40])\n",
      "y.shape is torch.Size([912, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4690139, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(288.719, 293.134), (176.393, 186.503), (44.275, 56.37), (65.98, 70.35), (248.463, 251.303), (34.884, 37.014), (189.958, 206.703), (18.883, 26.553), (50.418, 55.203), (254.361, 257.521), (180.827, 188.347), (157.289, 168.599), (126.906, 129.676), (87.472, 96.562), (101.208, 115.668), (223.068, 229.163), (1.647, 11.012), (111.642, 126.447), (66.258, 74.448), (235.177, 242.727), (160.244, 171.059), (71.144, 73.959), (28.199, 32.744), (142.502, 145.072)}\n",
      "Shape of mels: torch.Size([40, 18321])\n",
      "mel_length_time: 1.28\n",
      "num_data: 916\n",
      "X.shape is torch.Size([916, 40, 40])\n",
      "y.shape is torch.Size([916, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4346637, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(86.141, 93.596), (24.478, 29.493), (163.444, 170.409), (13.31, 29.175), (133.768, 136.838), (196.62, 216.51), (176.553, 179.103), (250.046, 253.176), (143.718, 163.403), (123.084, 125.089), (1.867, 12.767), (56.26, 60.93), (4.891, 12.831), (211.507, 225.442), (108.436, 119.831), (88.799, 104.819), (148.98, 162.88), (34.6, 37.14), (229.077, 233.027), (127.731, 132.741), (139.393, 148.843), (168.726, 177.551)}\n",
      "Shape of mels: torch.Size([40, 16980])\n",
      "mel_length_time: 1.28\n",
      "num_data: 848\n",
      "X.shape is torch.Size([848, 40, 40])\n",
      "y.shape is torch.Size([848, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4725457, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(131.539, 133.744), (151.166, 154.001), (156.874, 160.169), (117.888, 122.062), (12.714, 26.314), (66.029, 76.069), (23.151, 26.456), (81.552, 87.772), (33.58, 36.46), (208.071, 220.606), (27.92, 32.755), (60.509, 69.219), (236.403, 239.478), (95.024, 98.659), (248.648, 256.773), (35.408, 44.918), (210.715, 214.245), (26.59, 30.97), (268.578, 272.908), (170.837, 174.492), (80.314, 82.849), (168.799, 170.769), (194.635, 200.795), (186.774, 191.084)}\n",
      "Shape of mels: torch.Size([40, 18459])\n",
      "mel_length_time: 1.28\n",
      "num_data: 922\n",
      "X.shape is torch.Size([922, 40, 40])\n",
      "y.shape is torch.Size([922, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4757222, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(216.012, 229.318), (111.518, 118.208), (280.412, 283.012), (231.0, 240.185), (137.441, 142.966), (245.218, 272.118), (179.098, 182.298), (50.043, 64.183), (288.838, 296.903), (34.987, 46.162), (118.341, 121.156), (65.65, 72.045), (77.492, 81.752), (286.348, 292.848), (134.673, 152.453), (239.936, 242.511), (64.75, 67.565), (21.051, 23.756), (270.446, 272.591), (68.52, 71.03), (254.68, 260.39)}\n",
      "Shape of mels: torch.Size([40, 18583])\n",
      "mel_length_time: 1.28\n",
      "num_data: 928\n",
      "X.shape is torch.Size([928, 40, 40])\n",
      "y.shape is torch.Size([928, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4779105, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(231.253, 235.588), (25.65, 29.805), (3.101, 8.911), (31.804, 61.204), (264.224, 275.699), (291.834, 298.694), (289.714, 295.564), (3.678, 9.438), (203.857, 208.947), (170.101, 174.916), (137.2, 143.295), (256.344, 268.239), (220.322, 229.317), (93.014, 98.849), (279.254, 281.699), (127.411, 132.061), (16.315, 31.43), (247.264, 254.144), (184.742, 189.477), (139.879, 144.529), (78.041, 79.681), (10.667, 16.467), (200.899, 217.344), (95.982, 101.632), (109.437, 118.677), (38.311, 44.161), (209.63, 213.685), (72.476, 74.756), (124.01, 126.31), (229.322, 234.337)}\n",
      "Shape of mels: torch.Size([40, 18669])\n",
      "mel_length_time: 1.28\n",
      "num_data: 932\n",
      "X.shape is torch.Size([932, 40, 40])\n",
      "y.shape is torch.Size([932, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4709277, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(134.87, 137.27), (91.042, 104.982), (240.209, 242.819), (31.394, 33.954), (49.421, 63.111), (56.521, 66.201), (68.563, 74.548), (110.983, 113.868), (129.826, 133.716), (82.709, 90.224), (281.879, 293.139), (167.33, 176.57), (211.408, 220.332), (200.971, 224.481), (37.384, 45.544), (139.689, 148.739), (246.948, 250.498), (184.58, 190.775), (12.984, 22.339), (146.781, 155.736), (73.881, 83.256), (31.22, 48.77), (1.676, 9.256), (231.043, 239.063), (163.209, 165.054), (265.436, 270.646), (239.754, 250.684), (4.774, 7.469), (188.518, 196.158)}\n",
      "Shape of mels: torch.Size([40, 18396])\n",
      "mel_length_time: 1.28\n",
      "num_data: 918\n",
      "X.shape is torch.Size([918, 40, 40])\n",
      "y.shape is torch.Size([918, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4725905, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(206.411, 213.231), (249.278, 253.348), (41.323, 48.468), (257.122, 262.187), (199.609, 202.734), (233.64, 238.435), (182.093, 185.993), (285.469, 295.369), (34.945, 38.64), (175.315, 179.94), (202.821, 210.206), (76.307, 86.517), (93.331, 111.186), (180.396, 183.391), (27.478, 34.723), (290.229, 294.249), (253.131, 272.886), (222.222, 226.387), (230.844, 244.864), (210.674, 220.254), (139.208, 146.653), (111.987, 133.157), (22.055, 25.705)}\n",
      "Shape of mels: torch.Size([40, 18461])\n",
      "mel_length_time: 1.28\n",
      "num_data: 922\n",
      "X.shape is torch.Size([922, 40, 40])\n",
      "y.shape is torch.Size([922, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4776374, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(80.733, 83.268), (206.135, 221.605), (251.047, 253.347), (285.439, 293.564), (200.727, 204.752), (258.554, 263.779), (13.854, 19.949), (50.549, 54.494), (269.305, 272.725), (35.62, 38.65), (77.507, 80.217), (126.31, 132.16), (265.902, 280.672), (91.37, 96.43), (74.279, 91.704), (109.679, 118.184), (4.881, 9.821), (191.442, 200.537), (129.329, 131.299), (133.548, 136.313)}\n",
      "Shape of mels: torch.Size([40, 18658])\n",
      "mel_length_time: 1.28\n",
      "num_data: 932\n",
      "X.shape is torch.Size([932, 40, 40])\n",
      "y.shape is torch.Size([932, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4633252, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(229.941, 237.861), (267.244, 273.919), (160.742, 163.542), (179.76, 182.35), (77.245, 85.99), (94.239, 101.729), (148.71, 159.76), (15.63, 20.785), (216.052, 221.457), (170.927, 176.222), (38.358, 43.738), (280.238, 289.578), (92.433, 99.518), (48.642, 51.327), (65.574, 67.664), (108.481, 113.136), (181.449, 198.879), (184.219, 187.354), (251.425, 259.98), (107.382, 109.742), (28.321, 36.701), (249.285, 258.075), (204.937, 213.107), (138.769, 144.689)}\n",
      "Shape of mels: torch.Size([40, 18099])\n",
      "mel_length_time: 1.28\n",
      "num_data: 904\n",
      "X.shape is torch.Size([904, 40, 40])\n",
      "y.shape is torch.Size([904, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4627646, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(75.579, 78.504), (40.53, 45.355), (74.96, 98.37), (160.013, 169.753), (249.834, 252.534), (195.078, 199.554), (106.884, 109.574), (109.581, 125.281), (163.047, 165.817), (21.386, 31.15), (204.522, 206.712), (239.491, 253.786), (176.07, 183.056), (10.149, 18.424), (286.423, 288.808), (132.684, 135.939), (110.739, 115.384), (33.219, 38.079), (257.493, 260.953), (126.044, 132.494), (274.663, 289.228), (177.454, 182.169), (19.578, 25.633)}\n",
      "Shape of mels: torch.Size([40, 18077])\n",
      "mel_length_time: 1.28\n",
      "num_data: 902\n",
      "X.shape is torch.Size([902, 40, 40])\n",
      "y.shape is torch.Size([902, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4795820, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(98.701, 107.121), (223.762, 231.412), (290.773, 292.773), (235.017, 240.092), (63.326, 67.511), (286.794, 289.194), (252.701, 266.641), (197.256, 204.121), (206.561, 210.556), (125.086, 132.301), (169.889, 173.879), (296.269, 299.739), (173.022, 178.302), (257.882, 269.572), (181.164, 189.824), (103.745, 112.18), (5.539, 16.054), (155.535, 161.865), (9.989, 16.244), (193.338, 200.138), (206.899, 222.419), (269.863, 284.163), (111.9, 121.435), (277.524, 285.909), (94.044, 102.874), (32.269, 39.459), (137.62, 146.265)}\n",
      "Shape of mels: torch.Size([40, 18734])\n",
      "mel_length_time: 1.28\n",
      "num_data: 936\n",
      "X.shape is torch.Size([936, 40, 40])\n",
      "y.shape is torch.Size([936, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4765233, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(207.012, 210.272), (177.752, 181.377), (197.76, 200.035), (237.844, 242.824), (149.964, 156.789), (54.575, 67.88), (68.993, 77.508), (21.397, 26.307), (218.477, 224.772), (175.535, 182.87), (45.014, 50.034), (15.381, 22.481), (34.862, 38.167), (123.822, 130.992), (142.956, 149.886), (211.968, 219.403), (120.082, 123.722), (50.876, 55.956), (165.347, 168.972), (294.492, 297.827), (255.309, 257.629), (206.946, 209.546), (230.5, 246.95), (170.794, 173.289), (29.135, 32.615)}\n",
      "Shape of mels: torch.Size([40, 18615])\n",
      "mel_length_time: 1.28\n",
      "num_data: 930\n",
      "X.shape is torch.Size([930, 40, 40])\n",
      "y.shape is torch.Size([930, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4668201, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(138.592, 155.337), (165.756, 171.796), (226.821, 233.141), (181.674, 192.274), (214.748, 224.558), (84.684, 91.329), (79.131, 81.971), (206.508, 210.753), (186.591, 193.416), (251.908, 259.048), (225.907, 230.717), (156.817, 161.442), (146.103, 155.978), (58.861, 65.831), (100.755, 114.705), (193.262, 197.067), (25.119, 37.384), (41.708, 55.773), (259.864, 269.129), (100.488, 108.628), (284.542, 291.762)}\n",
      "Shape of mels: torch.Size([40, 18236])\n",
      "mel_length_time: 1.28\n",
      "num_data: 910\n",
      "X.shape is torch.Size([910, 40, 40])\n",
      "y.shape is torch.Size([910, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4511719, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(215.101, 222.396), (160.192, 163.952), (112.87, 118.47), (98.047, 108.492), (20.684, 23.944), (80.584, 90.574), (161.084, 168.859), (200.662, 206.222), (115.301, 133.746), (57.589, 70.339), (95.374, 99.919), (177.299, 189.499), (230.612, 238.982), (36.891, 47.136), (273.322, 281.982), (11.242, 16.222), (53.954, 69.039), (1.508, 10.858)}\n",
      "Shape of mels: torch.Size([40, 17624])\n",
      "mel_length_time: 1.28\n",
      "num_data: 880\n",
      "X.shape is torch.Size([880, 40, 40])\n",
      "y.shape is torch.Size([880, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4617195, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(279.115, 288.575), (17.729, 23.349), (191.923, 199.943), (76.288, 92.073), (271.977, 275.972), (222.922, 227.692), (270.888, 274.863), (82.899, 85.934), (67.53, 74.005), (62.291, 66.571), (17.0, 23.1), (198.145, 201.195), (176.885, 180.89), (119.06, 134.62), (37.873, 48.253), (175.989, 179.059), (145.061, 149.821), (156.112, 168.827), (150.016, 152.076), (49.325, 60.55), (136.264, 146.074), (181.695, 189.13)}\n",
      "Shape of mels: torch.Size([40, 18036])\n",
      "mel_length_time: 1.28\n",
      "num_data: 900\n",
      "X.shape is torch.Size([900, 40, 40])\n",
      "y.shape is torch.Size([900, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4582431, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(81.675, 98.09), (175.364, 183.899), (158.757, 170.757), (120.98, 126.4), (126.917, 131.617), (75.688, 82.802), (254.529, 269.204), (37.969, 53.489), (170.351, 181.481), (102.72, 113.9), (120.586, 126.931), (134.988, 144.338), (229.844, 244.314), (274.662, 286.402), (258.799, 261.079), (162.317, 166.912), (197.526, 213.011), (47.428, 54.733), (35.863, 40.183), (246.185, 251.345)}\n",
      "Shape of mels: torch.Size([40, 17901])\n",
      "mel_length_time: 1.28\n",
      "num_data: 894\n",
      "X.shape is torch.Size([894, 40, 40])\n",
      "y.shape is torch.Size([894, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4424512, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(250.257, 255.917), (197.207, 203.057), (0.484, 2.784), (211.486, 217.336), (139.038, 148.338), (112.984, 121.644), (125.563, 135.303), (219.021, 233.961), (98.087, 107.182), (46.06, 48.825), (217.779, 222.569), (33.656, 58.021), (123.774, 133.954), (17.942, 27.422), (236.886, 248.821), (157.183, 166.753), (109.675, 119.44), (66.36, 74.025), (33.53, 39.03), (269.682, 276.532), (63.933, 66.848), (255.306, 271.591), (79.812, 85.152)}\n",
      "Shape of mels: torch.Size([40, 17284])\n",
      "mel_length_time: 1.28\n",
      "num_data: 864\n",
      "X.shape is torch.Size([864, 40, 40])\n",
      "y.shape is torch.Size([864, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4671520, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(179.658, 182.218), (67.784, 78.144), (136.875, 142.2), (146.364, 161.009), (13.928, 22.658), (104.616, 106.691), (123.778, 144.728), (267.498, 269.973), (200.551, 204.081), (76.9, 81.63), (52.305, 64.62), (8.007, 10.807), (251.599, 259.649), (209.683, 241.058), (158.993, 167.543), (25.91, 45.29), (262.547, 268.547), (165.103, 172.118), (79.612, 96.352), (207.507, 220.907), (131.038, 136.524), (182.428, 196.838), (271.865, 281.72), (86.396, 104.046), (288.56, 291.97)}\n",
      "Shape of mels: torch.Size([40, 18249])\n",
      "mel_length_time: 1.28\n",
      "num_data: 912\n",
      "X.shape is torch.Size([912, 40, 40])\n",
      "y.shape is torch.Size([912, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4680381, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(171.941, 177.131), (257.654, 263.494), (48.204, 51.114), (75.502, 76.947), (161.507, 169.827), (255.364, 260.124), (222.638, 233.868), (99.947, 105.287), (146.042, 148.777), (220.251, 231.801), (24.848, 27.418), (242.219, 245.999), (282.414, 292.524), (95.856, 98.226), (98.501, 107.281), (30.222, 31.992), (288.112, 292.092), (252.112, 254.682), (275.785, 281.44), (162.19, 165.54), (207.95, 216.02)}\n",
      "Shape of mels: torch.Size([40, 18283])\n",
      "mel_length_time: 1.28\n",
      "num_data: 914\n",
      "X.shape is torch.Size([914, 40, 40])\n",
      "y.shape is torch.Size([914, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4737323, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(156.785, 163.15), (236.171, 238.876), (134.677, 137.992), (138.684, 144.284), (101.693, 116.778), (1.042, 4.877), (157.792, 162.207), (8.736, 13.586), (240.385, 249.405), (119.161, 125.176), (30.931, 37.516), (217.151, 226.436), (197.417, 201.442), (37.469, 48.324), (288.513, 296.083), (271.354, 275.278), (123.43, 127.396), (89.718, 96.713), (15.635, 34.56), (174.982, 178.382), (102.715, 105.59), (279.204, 282.224), (109.089, 113.339), (211.127, 228.447), (38.144, 44.559), (207.48, 210.98), (147.338, 153.058), (83.13, 94.934), (250.411, 253.961)}\n",
      "Shape of mels: torch.Size([40, 18506])\n",
      "mel_length_time: 1.28\n",
      "num_data: 924\n",
      "X.shape is torch.Size([924, 40, 40])\n",
      "y.shape is torch.Size([924, 1])\n",
      "Metadata: AudioMetaData(sample_rate=16000, num_frames=4797167, num_channels=1, bits_per_sample=32, encoding=PCM_F)\n",
      "{(30.827, 34.827), (129.596, 137.766), (12.014, 23.434), (7.487, 11.677), (103.473, 105.823), (133.359, 136.029), (148.176, 161.481), (244.366, 248.086), (98.366, 101.176), (113.195, 115.7), (61.984, 65.365), (161.928, 166.178), (8.847, 13.017), (237.013, 239.453), (178.688, 181.693), (240.068, 251.054), (233.83, 239.355), (230.85, 235.855), (176.319, 184.444), (209.234, 211.304), (289.638, 299.283), (34.346, 42.926)}\n",
      "Shape of mels: torch.Size([40, 18739])\n",
      "mel_length_time: 1.28\n",
      "num_data: 936\n",
      "X.shape is torch.Size([936, 40, 40])\n",
      "y.shape is torch.Size([936, 1])\n",
      "X.shape is: torch.Size([45494, 40, 40])\n",
      "y.shape is: torch.Size([45494, 1])\n"
     ]
    }
   ],
   "source": [
    "def createDataset(root, num_sessions):\n",
    "    X = []\n",
    "    y = []\n",
    "    for session in range(num_sessions):\n",
    "        session_X, session_y = createDataFromRecording(session_root=root + \"session_\" + str(session), id=session)\n",
    "        assert torch.is_tensor(session_X) and torch.is_tensor(session_y) \n",
    "        assert session_X.shape[1] == num_mel_bands and session_X.shape[1] == num_mel_bands and session_y.shape[1] == 1 and session_X.shape[0] == session_y.shape[0]\n",
    "\n",
    "        X.append(session_X)\n",
    "        y.append(session_y)\n",
    "    X = torch.cat(X, dim=0)\n",
    "    y = torch.cat(y, dim=0)\n",
    "\n",
    "    print(f'X.shape is: {X.shape}')\n",
    "    print(f'y.shape is: {y.shape}')\n",
    "\n",
    "createDataset(root='LibriParty/dataset/dev/', num_sessions=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSP_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
